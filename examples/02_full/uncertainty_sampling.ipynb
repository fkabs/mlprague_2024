{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlocking the Power of Active Learning: A Hands-on Exploration\n",
    "\n",
    "Fabian Kovac [\\<fabian.kovac@fhstp.ac.at\\>](mailto:fabian.kovac@fhstp.ac.at)\n",
    "\n",
    "Oliver Eigner[<oliver.eigner@fhstp.ac.at\\>](mailto:oliver.eigner@fhstp.ac.at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets._samples_generator import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from learner import ActiveLearner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SEED\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples to query at each iteration\n",
    "N_SAMPLES = 20\n",
    "\n",
    "# number of active learning iterations\n",
    "N_QUERIES = 100\n",
    "\n",
    "# percentage of human labeling error\n",
    "HUMAN_ERROR = 0.05\n",
    "\n",
    "# model to test (support vector machine with radial basis function kernel)\n",
    "MODEL = SVC(kernel = 'rbf', C = 13, gamma = 0.8, probability = True, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib styles\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (7, 4)\n",
    "plt.rcParams['image.cmap'] = 'Dark2'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting svc decision boundaries\n",
    "def plot_svc_decision_function(model, ax = None, plot_support = False):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    x = np.linspace(xlim[0], xlim[1])\n",
    "    y = np.linspace(ylim[0], ylim[1])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "\n",
    "    ax.contour(X, Y, P, colors = ['crimson'], levels = [0], alpha = 1, linestyles = ['-'])\n",
    "    \n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s = 300, lw = 1, facecolors = 'crimson', alpha = 0.2)\n",
    "        ax.contour(X, Y, P, colors = ['crimson', 'crimson'], levels = [-1, 1], alpha = 0.3, linestyles = ['--', '--'])\n",
    "        \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting active learning history\n",
    "def plot_history(history, X_train, X_test, y_test, centralized_test_acc, show_models = False):\n",
    "    # plot each model state in the active learning history\n",
    "    # plotting decision boundaries is only implemented for SVC models for now\n",
    "    if show_models and type(history[0]['model']) == SVC:\n",
    "        for i, ret in history.items():\n",
    "            model = ret['model']\n",
    "            X_i = ret['X']\n",
    "            y_i = ret['y']\n",
    "            \n",
    "            # model metrics\n",
    "            train_acc = round(model.score(X_i, y_i), 3)\n",
    "            test_acc = round(model.score(X_test, y_test), 3)\n",
    "            \n",
    "            # generate two subplots, one for the training data (active learning iteratin) and one for the test data\n",
    "            fig, ax = plt.subplots(1, 2, figsize = (14, 4))\n",
    "            fig.suptitle(f'Active Learning Model', fontsize = 16, fontweight = 'bold')\n",
    "            plt.subplots_adjust(top = 0.8)\n",
    "\n",
    "            ax[0].title.set_text(f'Training Iteration {i} | Acc: {train_acc}')\n",
    "            ax[0].scatter(X_train[:, 0], X_train[:, 1], c = 'lightgray', alpha = 1, s = 40)\n",
    "            ax[0].scatter(X_i[:, 0], X_i[:, 1], c = y_i, s = 40)\n",
    "            plot_svc_decision_function(model, ax[0])\n",
    "\n",
    "            ax[1].title.set_text(f'Test data | Acc: {test_acc}')\n",
    "            ax[1].scatter(X_test[:, 0], X_test[:, 1], c = y_test, s = 40)\n",
    "            plot_svc_decision_function(model, ax[1])\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "    # linegraph of model accuracy over iterations compared to centralized model\n",
    "    plt.axhline(y = centralized_test_acc, color = 'gray', linestyle = '--', label = 'Centralized Test Accuracy')\n",
    "    \n",
    "    test_accs = [ret['model'].score(X_test, y_test) for ret in history.values()]\n",
    "    plt.plot(test_accs, label = 'Active Learning Test Accuracy')    \n",
    "    \n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "X, y = make_classification(\n",
    "    n_samples = 1000, n_features = 2, n_classes = 2,\n",
    "    n_informative = 2, n_redundant = 0, n_clusters_per_class = 2, class_sep = 0.85,\n",
    "    random_state = SEED)\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = SEED)\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c = y_train, s = 40);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Centralized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a centralized model\n",
    "centralized_model = deepcopy(MODEL)\n",
    "centralized_model.fit(X_train, y_train)\n",
    "\n",
    "# model metrics\n",
    "train_acc = round(centralized_model.score(X_train, y_train), 3)\n",
    "test_acc = round(centralized_model.score(X_test, y_test), 3)\n",
    "\n",
    "# plot decision boundaries\n",
    "fig, ax = plt.subplots(1, 2, figsize = (14, 4))\n",
    "fig.suptitle(f'Centralized model', fontsize = 16, fontweight = 'bold')\n",
    "plt.subplots_adjust(top = 0.8)\n",
    "\n",
    "ax[0].title.set_text(f'Training data | Acc: {train_acc}')\n",
    "ax[0].scatter(X_train[:, 0], X_train[:, 1], c = y_train, s = 40)\n",
    "plot_svc_decision_function(centralized_model, ax[0])\n",
    "\n",
    "ax[1].title.set_text(f'Test data | Acc: {test_acc}')\n",
    "ax[1].scatter(X_test[:, 0], X_test[:, 1], c = y_test, s = 40)\n",
    "plot_svc_decision_function(centralized_model, ax[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Active Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seed to ensure same initial model\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Active Learning using Random Sampling\n",
    "learner = ActiveLearner(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    model = deepcopy(MODEL),\n",
    "    n_samples = N_SAMPLES,\n",
    "    n_queries = N_QUERIES,\n",
    "    strategy = 'random',\n",
    "    human_error = HUMAN_ERROR\n",
    ")\n",
    "\n",
    "history = learner.fit()\n",
    "\n",
    "plot_history(history, X_train, X_test, y_test, test_acc, show_models = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Confidence Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seed to ensure same initial model\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Active Learning using least confidence sampling\n",
    "learner = ActiveLearner(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    model = deepcopy(MODEL),\n",
    "    n_samples = N_SAMPLES,\n",
    "    n_queries = N_QUERIES,\n",
    "    strategy = 'least_conf',\n",
    "    human_error = HUMAN_ERROR\n",
    ")\n",
    "\n",
    "history = learner.fit()\n",
    "\n",
    "plot_history(history, X_train, X_test, y_test, test_acc, show_models = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Margin Confidence Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seed to ensure same initial model\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Active Learning using margin confidence sampling\n",
    "learner = ActiveLearner(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    model = deepcopy(MODEL),\n",
    "    n_samples = N_SAMPLES,\n",
    "    n_queries = N_QUERIES,\n",
    "    strategy = 'margin_conf',\n",
    "    human_error = HUMAN_ERROR\n",
    ")\n",
    "\n",
    "history = learner.fit()\n",
    "\n",
    "plot_history(history, X_train, X_test, y_test, test_acc, show_models = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio Confidence Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seed to ensure same initial model\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Active Learning using ratio confidence sampling\n",
    "learner = ActiveLearner(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    model = deepcopy(MODEL),\n",
    "    n_samples = N_SAMPLES,\n",
    "    n_queries = N_QUERIES,\n",
    "    strategy = 'ratio_conf',\n",
    "    human_error = HUMAN_ERROR\n",
    ")\n",
    "\n",
    "history = learner.fit()\n",
    "\n",
    "plot_history(history, X_train, X_test, y_test, test_acc, show_models = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seed to ensure same initial model\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Active Learning using entropy sampling\n",
    "learner = ActiveLearner(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    model = deepcopy(MODEL),\n",
    "    n_samples = N_SAMPLES,\n",
    "    n_queries = N_QUERIES,\n",
    "    strategy = 'entropy',\n",
    "    human_error = HUMAN_ERROR\n",
    ")\n",
    "\n",
    "history = learner.fit()\n",
    "\n",
    "plot_history(history, X_train, X_test, y_test, test_acc, show_models = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
